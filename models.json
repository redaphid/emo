[
  {
    "id": "tinyllama-1.1b-q4",
    "name": "TinyLlama 1.1B Q4_K_M",
    "url": "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
    "size_mb": 669,
    "description": "Tiny but capable, fast inference"
  },
  {
    "id": "phi-2-q4",
    "name": "Phi-2 2.7B Q4_K_M",
    "url": "https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q4_K_M.gguf",
    "size_mb": 1600,
    "description": "Microsoft's compact model, good quality"
  },
  {
    "id": "gemma-2b-q4",
    "name": "Gemma 2B Q4_K_M",
    "url": "https://huggingface.co/lmstudio-ai/gemma-2b-it-GGUF/resolve/main/gemma-2b-it-q4_k_m.gguf",
    "size_mb": 1500,
    "description": "Google's efficient small model"
  },
  {
    "id": "qwen2.5-0.5b-q4",
    "name": "Qwen 2.5 0.5B Q4_K_M",
    "url": "https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct-GGUF/resolve/main/qwen2.5-0.5b-instruct-q4_k_m.gguf",
    "size_mb": 394,
    "description": "Smallest model, very fast"
  },
  {
    "id": "stablelm-2-1.6b-q4",
    "name": "StableLM 2 1.6B Q4_K_M",
    "url": "https://huggingface.co/second-state/stablelm-2-zephyr-1.6b-GGUF/resolve/main/stablelm-2-zephyr-1_6b-Q4_K_M.gguf",
    "size_mb": 977,
    "description": "Stable LM 2, balanced performance"
  }
]